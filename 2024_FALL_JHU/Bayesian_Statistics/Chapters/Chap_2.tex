\chapter{Multi-Parameter Models}
In the previous chapter, we introduced the idea of Bayesian Statistics, two one-parameter models, and one-parameter exponential family. In this chapter, we will go explore models with multiple parameters, together with some advanced ideas. 

\section{The most objective: Jeffreys' Prior}
When we are trying to select a prior, we often turn to the uniform distribution if we have no idea about how the parameters are distributed. Uniform is believed to be objective because all possible parameters are assigned with the same weight, meaning we are not favoring any particular options. But it's far from being perfect, because if so, this section won't exist. In this section, we will first explain why uniform can be problematic sometimes, and then introduce the Jeffreys' prior, which is believed to be more objective to some.

One of the good sides of using uniform as prior is that, as long as you are selecting the parameter(s) within a finite region, you don't need to adjust the weight since it will be offset in the normalization factor afterall. However, if $|\Omega| = \infty$ for example $[0, +\infty), (-\infty, 0]$, then the integration of the prior is bound to be infinite. The problem is that, not only the decomposition $\bf{P}(Y=y) = \int_{\Omega} \bf{P}(Y=y|\theta) d\theta$ will very likely to be invalid because the integration might not converge. In addition, even if it converges, uniform prior with $\pi(\theta) = 1$ becomes less objective because now it tends to favor larger $\theta$ since for all finite interval/region $I$, $\int_{I} \pi(\theta) d\theta < \infty$ but $\int_{\Omega\setminus I}\pi(\theta)d\theta = \infty$. 

Apart from infinite regions, uniform prior also doesn't work well with change of variables. Take the following as an example:
\begin{example}
    Let $\theta \sim Unif(0,1)$ and odds $\tau = \frac{\theta}{1-\theta}$. Then we have $\theta = \frac{\tau}{1+\tau}$ and $\frac{d\theta}{d\tau} = \frac{1}{(1+\tau)^2}$. Using the formula for  change of variable, we have $pdf(\tau) = \pi(\theta(\tau))\frac{d\theta}{d\tau} = \frac{1}{(1+\tau)^2},\; \tau \in (0, +\infty)$.
\end{example}

To address these issues, mostly on the second one, we introduce Jeffreys' Prior
\begin{equation*}
    \pi(\theta) = \sqrt{I(\theta)}
\end{equation*}
where $I(\theta)$ is the \emph{Fisher Information} with $I(\theta) = - \mathbb{E}[\frac{\partial^2 \log p(y|\theta)}{\partial\theta^2} | \theta] = -\mathbb{E}[\frac{\partial^2 \log L}{\partial \theta^2} | \theta]$. It's not intuitive at the first glance, but the following property enbales Fisher Information to be a part of the prior.

\begin{proposition}
    \begin{equation*}
        I(\theta) = - \mathbb{E}[\frac{\partial^2 \log L}{\partial \theta^2}] = \mathbb{E}[( \frac{\partial \log L}{\partial \theta} )^2]
    \end{equation*}
\end{proposition}

With this property, we can prove that Jeffreys' prior is invariable under change of variables. In other words, we have:
\begin{theorem}
    With $\phi = \phi(\theta)$ and $p(\theta) \propto \sqrt{I(\theta)}$, we have $p(\phi) \propto \sqrt{I(\phi)}$.
\end{theorem}

One question one may have right now is why is Jeffreys' prior objective? Clearly it doesn't assign the same weight on all possible parameter candidates since it's not a uniform. The answer is, Jeffreys' Prior is in fact the maximizer of the KL-divergence bewteen the prior and posterior distribution. In this sense, Jeffreys' prior is objective because it "allows" the data to speak the most of it. Apparently, this idea can be philosophical and up to individual's personal perspective, but at least mathematically it's a handy wrench in the toolbox by introducing invariability to reparametrization. 

\begin{note}[The maximizer of KL-divergence]
    TBD
\end{note}
\section{The Normal Model}