\chapter{Multi-Parameter Models}
In the previous chapter, we introduced the idea of Bayesian Statistics, two one-parameter models, and one-parameter exponential family. In this chapter, we will go explore models with multiple parameters, together with some advanced ideas. 

\section{The most objective: Jeffreys' Prior}
When we are trying to select a prior, we often turn to the uniform distribution if we have no idea about how the parameters are distributed. Uniform is believed to be objective because all possible parameters are assigned with the same weight, meaning we are not favoring any particular options. But it's far from being perfect, because if so, this section won't exist. In this section, we will first explain why uniform can be problematic sometimes, and then introduce the Jeffreys' prior, which is believed to be more objective to some.

One of the good sides of using uniform as prior is that, as long as you are selecting the parameter(s) within a finite region, you don't need to adjust the weight since it will be offset in the normalization factor afterall. However, if $|\Omega| = \infty$ for example $[0, +\infty), (-\infty, 0]$, then the integration of the prior is bound to be infinite. The problem is that, not only the decomposition $\mathbf{P}(Y=y) = \int_{\Omega} \mathbf{P}(Y=y|\theta) d\theta$ will very likely to be invalid because the integration might not converge. In addition, even if it converges, uniform prior with $\pi(\theta) = 1$ becomes less objective because now it tends to favor larger $\theta$ since for all finite interval/region $I$, $\int_{I} \pi(\theta) d\theta < \infty$ but $\int_{\Omega\setminus I}\pi(\theta)d\theta = \infty$. 

Apart from infinite regions, uniform prior also doesn't work well with change of variables. Take the following as an example:
\begin{example}
    Let $\theta \sim Unif(0,1)$ and odds $\tau = \frac{\theta}{1-\theta}$. Then we have $\theta = \frac{\tau}{1+\tau}$ and $\frac{d\theta}{d\tau} = \frac{1}{(1+\tau)^2}$. Using the formula for  change of variable, we have $pdf(\tau) = \pi(\theta(\tau))\frac{d\theta}{d\tau} = \frac{1}{(1+\tau)^2},\; \tau \in (0, +\infty)$.
\end{example}

To address these issues, mostly on the second one, we introduce Jeffreys' Prior
\begin{equation*}
    \pi(\theta) = \sqrt{I(\theta)}
\end{equation*}
where $I(\theta)$ is the \emph{Fisher Information} with $I(\theta) = - \mathbb{E}[\frac{\partial^2 \log p(y|\theta)}{\partial\theta^2} | \theta] = -\mathbb{E}[\frac{\partial^2 \log L}{\partial \theta^2} | \theta]$. It's not intuitive at the first glance, but the following property enbales Fisher Information to be a part of the prior.

\begin{proposition}
    \begin{equation*}
        I(\theta) = - \mathbb{E}[\frac{\partial^2 \log L}{\partial \theta^2}] = \mathbb{E}[( \frac{\partial \log L}{\partial \theta} )^2]
    \end{equation*}
\end{proposition}

With this property, we can prove that Jeffreys' prior is invariable under change of variables. In other words, we have:
\begin{theorem}
    With $\phi = \phi(\theta)$ and $p(\theta) \propto \sqrt{I(\theta)}$, we have $p(\phi) \propto \sqrt{I(\phi)}$.
\end{theorem}

One question one may have right now is why is Jeffreys' prior objective? Clearly it doesn't assign the same weight on all possible parameter candidates since it's not a uniform. The answer is, Jeffreys' Prior is in fact the maximizer of the KL-divergence bewteen the prior and posterior distribution. In this sense, Jeffreys' prior is objective because it "allows" the data to speak the most of it. Apparently, this idea can be philosophical and up to individual's personal perspective, but at least mathematically it's a handy wrench in the toolbox by introducing invariability to reparametrization. 

\begin{note}[The maximizer of KL-divergence]
    TBD
\end{note}

\section{The Normal Model}
Normal distribution will be the first multi-parameter model we are going to study. The methodology is intuitive, instead of modeling two parameters at a time, we first fix $\sigma^2$ as a constant, which now equals to a one-parameter model. Then, we introduce $\sigma^2$ as a random variable and repeat the procedure. 

\subsection{Condition Posterior}
We have joint sampling density as the product of $n$ normal due to conditional independence
\begin{align}
    \mathbf{P}(y_1, \ldots, y_n | \theta, \sigma^2) &\propto \prod_{i=1}^{n}\exp(-\frac{1}{2\sigma^2}(y_i - \theta)^2) \\
    &=\exp(-\frac{1}{2\sigma^2}\sum_{i=1}^{n}(y_i - \theta)^2) \\
    &=\exp(-\frac{1}{2}(\frac{n}{\sigma^2}\theta^2 - 2\frac{\sum y_i}{\sigma^2} + \frac{\sum y_i^2}{\sigma^2})) \label{eq:NormalConditionalSamplingDecomposition}\\
    &=\exp(c_1(\theta - c_2)^2 + c_3)
\end{align}

By fixing $\sigma^2$ as a constant, we have conditional posterior
\begin{align}
    \mathbf{P}(\theta | y_1, \ldots, y_n, \sigma^2) &\propto \mathbf{P}(y_1, \ldots, y_n | \theta, \sigma^2) \cdot \mathbf{P}(\theta | \sigma^2)  \label{eq:NormalConditionalPosterior}
\end{align}

To make it conjugate, one straightforward choice for prior is also normal, specifically $N(\mu_0, \tau_0^2)$. Then we have the following decomposition of the prior pdf:
\begin{align}
    \mathbf{P}(\theta | \sigma^2) &\propto \exp(- \frac{1}{2\tau_0^2}(\theta - \mu_0)) \\
    &=\exp(-\frac{1}{2}(\frac{1}{\tau_0^2}\theta^2 - 2\frac{\mu_0}{\tau_0^2}\theta + \frac{\mu_0^2}{\tau_0^2})) \label{eq:NormalConditionalPriorDecomposition}\\
    &=\exp(-\frac{1}{2}(a\theta^2 - 2b\theta^2 +c))
\end{align}
This expression offers us a quick way to compute the mean and gradient of the normal distribution:
\begin{equation}
    \tau_0^2 = \frac{1}{a}, \quad \mu_0 = b \cdot \tau_0^2 = \frac{b}{a} \label{eq:QuickNormalMeanVarFormula}
\end{equation}

Now we have collected all of the ingredients we need, by combining (\ref{eq:NormalConditionalSamplingDecomposition}) and (\ref{eq:NormalConditionalPriorDecomposition}) into (\ref{eq:NormalConditionalPosterior}), we obtain the following decomposition:
\begin{equation}
    \mathbf{P}(\theta | y_1, \ldots, y_n, \sigma^2) \propto \exp(-\frac{1}{2}\big[ (\frac{n}{\sigma^2} + \frac{1}{\tau_0^2})\theta^2 - 2(\frac{\sum y_i}{\sigma^2} + \frac{\mu_0}{\tau_0^2})\theta + (\frac{\sum y_i^2}{\sigma^2} + \frac{\mu_0^2}{\tau_0^2}) \big])
\end{equation}

By using the formula (\ref{eq:QuickNormalMeanVarFormula}) and substituting the variance terms with precision, we obtain conditional posterior mean and variance:
\begin{equation*}
    \tau_n^2 = \frac{1}{a} = \frac{1}{n\tilde{\sigma}^2 + \tilde{\tau_0}^2}, \quad \mu_n = \frac{b}{a} = \frac{\sum y_i \tilde{\sigma}^2 + \mu_0\tilde{\tau_0}^2}{n\tilde{\sigma}^2 + \tilde{\tau_0}^2}
\end{equation*}
which means we have the conditional postertior
\begin{equation*}
    \theta | y_1, \ldots, y_n, \sigma^2 \sim N(\mu_n, \tau_n^2)
\end{equation*}

\subsection{Law of Total Expectation/Variance}
Conditional expectation $\mathbb{E}[U|V=v]$ is a random variable in $V$, which means its value changes according to $V$. The low of total expectation states that 
\begin{equation*}
    \mathbb{E}[\mathbb{E}[U|V]] = \mathbb{E}[U]
\end{equation*}\
The proof is quite simple, by writing the left hand side explicitly:
\begin{align*}
    &\int_{V}\int_{U|V=v}u \cdot p(U=u|V=v) du \cdot p(V=v)dv \\
    =& \int_{V}\int_{U|V=v}u \cdot p(U=u) dudv \\
    =& \int_{V}\int_{U}u \cdot p(U=u) dudv \\
    =& \int_{V} \mathbb{E}[U] dv = \mathbb{E}[U]
\end{align*}

By doing something similar, we derive the law of total variance:
\begin{equation*}
    Var(U) = \mathbb{E}[Var(U|V)] + Var(\mathbb{E}[U|V])
\end{equation*}